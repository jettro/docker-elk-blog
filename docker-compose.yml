version: '3.2'

services:
  elasticsearch:
    build:
      context: elasticsearch/
      args:
        ELK_VERSION: $ELK_VERSION
    volumes:
      - type: bind
        source: ./elasticsearch/config/elasticsearch.yml
        target: /usr/share/elasticsearch/config/elasticsearch.yml
        read_only: true
      - type: bind
        source: ./elasticsearch/data
        target: /usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: "-Xmx1g -Xms1g"
      ELASTIC_PASSWORD: $ES_PASSWORD
    healthcheck:
      test: ["CMD", "curl","-s" ,"-f", "-u", "elastic:${ES_PASSWORD}", "http://localhost:9200/_cat/health"]
    networks:
      - elk

  logstash:
    build:
      context: logstash/
      args:
        ELK_VERSION: $ELK_VERSION
    volumes:
      - type: bind
        source: ./logstash/config/logstash.yml
        target: /usr/share/logstash/config/logstash.yml
        read_only: true
      - type: bind
        source: ./logstash/config/pipelines.yml
        target: /usr/share/logstash/config/pipelines.yml
        read_only: true
      - type: bind
        source: ./logstash/pipeline
        target: /usr/share/logstash/pipeline
        read_only: true
      - type: bind
        source: ./logstash/data
        target: /var/lib/logstash/data
    ports:
      - "9101:5000/tcp"
      - "9101:5000/udp"
      - "8003:8003"
      - "9600:9600"
    command: --config.reload.automatic 
    environment:
      - "LS_JAVA_OPTS=-Xmx1g -Xms1g"
      - "ELASTICSEARCH_PASSWORD=${ES_PASSWORD}"
    networks:
      - elk
    depends_on:
      - elasticsearch

  kibana:
    build:
      context: kibana/
      args:
        ELK_VERSION: $ELK_VERSION
    volumes:
      - type: bind
        source: ./kibana/config/kibana.yml
        target: /usr/share/kibana/config/kibana.yml
        read_only: true
    ports:
      - "5601:5601"
    environment:
      - "ELASTICSEARCH_PASSWORD=${ES_PASSWORD}"
    healthcheck:
      test: ["CMD", "curl", "-s", "-f", "http://localhost:5601/login"]
      retries: 6      
    networks:
      - elk
    depends_on:
      - elasticsearch

  heartbeat:
    build:
      context: beats/heartbeat
      args:
        ELK_VERSION: $ELK_VERSION
    volumes:
      #Mount the heartbeat configuration so users can make edits
      - ./beats/heartbeat/config/heartbeat.yml:/usr/share/heartbeat/heartbeat.yml
    depends_on:
      - elasticsearch
    environment:
      - "ELASTICSEARCH_PASSWORD=${ES_PASSWORD}"
      - "ELASTICSEARCH_HOSTS=elasticsearch:9200"
      - "ELASTICSEARCH_USERNAME=elastic"
    command: heartbeat -e -strict.perms=false
    networks:
      - elk
    restart: on-failure

  #Metricbeat container
  metricbeat:
    build:
      context: beats/metricbeat
      args:
        ELK_VERSION: $ELK_VERSION
    user: root
    volumes:
      #Mount the metricbeat configuration so users can make edit
      - ./beats/metricbeat/config/metricbeat.yml:/usr/share/metricbeat/metricbeat.yml
      #Mount the modules.d directory into the container. This allows user to potentially make changes to the modules and they will be dynamically loaded.
      - ./beats/metricbeat/config/modules.d/:/usr/share/metricbeat/modules.d/
      #The commented sections below enable Metricbeat to monitor the Docker host rather than the Metricbeat container. These are used by the system module.
      - /proc:/hostfs/proc:ro
      - /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro
      #Allows us to report on docker from the hosts information
      - /var/run/docker.sock:/var/run/docker.sock
      #We mount the host filesystem so we can report on disk usage with the system module
      - /:/hostfs:ro
    command: metricbeat -e -system.hostfs=/hostfs -E output.elasticsearch.username=elastic -E output.elasticsearch.password=${ES_PASSWORD} -strict.perms=false
    networks:
      - elk
    restart: on-failure
    environment:
      - "ELASTICSEARCH_PASSWORD=${ES_PASSWORD}"
      - "ELASTICSEARCH_HOSTS=elasticsearch:9200"
      - "ELASTICSEARCH_USERNAME=elastic"
    depends_on:
      #wait for the these services to come up. This ensures the logs are available and ES exists for indexing
      - elasticsearch

networks:
  elk:
    driver: bridge

volumes:
  elasticsearch:
